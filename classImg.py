"""
refactored 10/6/2015

performs logistic regression on input images
tries to tell positively labelled images apart from negatively labelled images

has two main functions:
    binary classification
    one vs all (multi) classification

also contains:
    classifyImage
        classifies a given image into one of two categories
        does not accept one vs all

TO DO:
unite binary Classify and multiClassify
"""

import os
import numpy as np
import cv2 as cv
import matplotlib.pyplot as plt
from logReg import *

def binaryClassify():
    """
    this algorithm classifies images based on the sum of R,G,B respectively for each column of the image
    labelled images must be named <name>YES.png or <name>NOT.png
    """
    # ===== load data for processing ===== #

    numColumns = 13
    numColors = 3
    folderName = 'commCard'
    dataType = 'commCard'
    saveData = True

    n = numColumns*numColors
    (X,y,m) = loadBinData(folderName,n)
                
    print y[y==1].size,'positive and',y[y==0].size,'negative examples'

    if saveData:
        # save data to .csv file
	Z = np.zeros((m,n+1))   # stores X and y when it is passed to csv file
	Z[:,0:n]    = X.copy()
        Z[:,n]      = y.copy()

        saveName = dataType+'Data.csv'
        np.savetxt(saveName,Z,delimiter=',')
        print 'training data saved to ',saveName

    # ===== logistic regression ===== #

    print 'start logistic regression...'
    (X_norm, mu, sigma) = featureNormalize(X)
    theta = logisticRegression(X_norm,y,dataType)
    print '... finished'

    if saveData:
        # save results to .csv file
        saveName = dataType+'Theta.csv'
        numCat = 1
        numFeat = n+1
        catNames=['binary']
        comments = 'theta values for '+dataType
        saveResults(saveName,numCat,numFeat,dataType,catNames,comments,theta,mu,sigma)
    
    testResults(X_norm,y,theta,mu,sigma)

# =============================================================================== #



def testResults(X,y,theta,mu,sigma):
    # assume Xo already added to X, mu, sigma
    # assume X already normalised
    m = float(X.shape[0])
    yCalcRaw = np.dot(X,theta)
    yCalc = sigmoid(yCalcRaw)#write unit tests for everything
    yCalc[yCalc>0.5] = 1
    yCalc[yCalc<=0.5] = 0
    correct = 100*(yCalc==y).sum()/m
    print 'hypothesis generated by logistic regression produces ',correct,' percent \ncorrect classifications of training data'



# =============================================================================== #


def multiClassify():
    """
    one vs all classification for binary images
    this algorithm classifies images based on the sum of binary column pixels for each column and row of the image
    images must have already been proccessed RGB->binary->RGB
    this script assumes that every category fed to the algorithm has useful data in it
    """
    
    # ===== user input ===== #
    # 13x7 for card face values

    numFeatA        = 5     # columns
    numFeatB        = 8	     # rows
    numCat          = 10
    catNames	    = ['0','1','2','3','4','5','6','7','8','9']
    #catNames        = ['2','3','4','5','6','7','8','9','10','J','Q','K','A']
    #catNames        = ['club','diamond','heart','spade']
    #catNames        = ['0','1','2','3','4','5','6','7','8','9','A','S']
    dataLocation    = 'elementLibrary/processed/betDigits/'
    dataType        = 'betDigit'
    saveData        = True
    
    for c in range(numCat):
        # ===== load up data ===== #
        dataName = catNames[c]
        
        # get positive training examples
        posFolderName = dataName
        DIRpos = os.path.normpath(dataLocation+posFolderName)
        imageListPos = [name for name in os.listdir(DIRpos)if os.path.isfile(os.path.join(DIRpos, name))]
        numPos = len(imageListPos)

        # get all negative training examples
        if c == 0:
            negFolderRange = range(1,numCat)
        elif c == numCat-1:
            negFolderRange = range(0,numCat-1)
        else:
            negFolderRange = range(0,c)+range(c+1,numCat)

        imageListNeg = [None for x in negFolderRange]
        numNeg  = [None for x in negFolderRange]
        k = 0
        for i in negFolderRange:
            DIRneg = os.path.normpath(dataLocation+catNames[i])
            imageListNeg[k] = [name for name in os.listdir(DIRneg)if os.path.isfile(os.path.join(DIRneg, name))]
            numNeg[k] = len(imageListNeg[k])
            k +=1
        sumNumNeg = sum(numNeg)

        # ===== initialize calculation matrices ===== #
        
        m = numPos + sumNumNeg      # number of training examples
        n = numFeatA+numFeatB       # number of features per example
       
        print m,'training examples'
        print 'with',numPos,'positive and',sumNumNeg,'negative examples'
        
        X = np.zeros((m,n))         # input examples for training
        y = np.zeros(m)             # output examples for training
        Z = np.zeros((m,n+1))       # stores X and y when it is passed to csv file

        # ===== fill calculation matrices with image data ===== #
        
        # load positive example features from positive example images
        for i in range(numPos):
            imageName = imageListPos[i] 
            y[i] = 1                   
            readPath = os.path.normpath(DIRpos+'/'+imageName)  
            imgArrRGB = cv.imread(readPath,1) # assume RGB image has been processed already            
            X[i,:] = buildX(imgArrRGB,dataType,numFeatA,numFeatB)
        

        # for each negative category, load negative example features from negative example images
        row = numPos # start count from here
        for i in range(numCat-1):
            folder = negFolderRange[i]
            DIRneg = os.path.normpath(dataLocation+catNames[folder])
            for j in range(numNeg[i]):
                imageName = imageListNeg[i][j] 
                y[row] = 0
                readPath = os.path.normpath(DIRneg+'/'+imageName)
                imgArrRGB = cv.imread(readPath,1) # assume RGB image has been processed already 
                X[row,:] = buildX(imgArrRGB,dataType,numFeatA,numFeatB)
                row +=1

  
        # ===== save data for this category regression ===== #
        if saveData:
            # save data to .csv file
            Z[:,0:n]    = X.copy()
            Z[:,n]      = y.copy()

            saveName = dataType+dataName+'Data.csv'
            np.savetxt(saveName,Z,delimiter=',')
            print 'training data saved to ',saveName
        
        # ===== run one vs all logistic regression ===== #
        print 'start logistic regression...'
        (X_norm, mu, sigma) = featureNormalize(X)
        theta = logisticRegression(X_norm,y)
        print '... finished'
        
        if saveData:
            # save results to .csv file
            saveName = dataType+dataName+'Theta.csv'
            comments = 'theta values for '+dataName
            saveResults(saveName,numCat=1,numFeat=n+1,dataType=dataType,catNames=['binary'],
                        comments=comments,theta=theta,mu=mu,sigma=sigma)
            
        # test single logistic regression
        testResults(X_norm,y,theta,mu,sigma)

    # ===== collate all category data into a single file ===== #
    if saveData:
        # initialise save matrices
        numFeat = n+1
        theta   = np.zeros((numFeat,numCat))
        mu      = np.zeros((numFeat,numCat))
        sigma   = np.zeros((numFeat,numCat))
        # load parameters from each category
        for c in range(numCat):
            readName    = dataType+catNames[c]+'Theta.csv'
            (numFeat_c,dataType_c,theta_c,mu_c,sigma_c) = loadResults(readName,loadMulti=False)
            theta[:,c]  = theta_c
            mu[:,c]     = mu_c 
            sigma[:,c]  = sigma_c
        # save collated parameters to .csv file
        saveName = dataType+'Theta.csv'
        comments = 'collated theta values'
        saveResults(saveName,numCat,numFeat,dataType,catNames,comments,theta,mu,sigma)

    # ===== test one vs all classification ===== #

    # load all theta values
    readName = dataType+'Theta.csv'
    (numCat,numFeat,dataType,catNames,theta,mu,sigma) = loadResults(readName)
    

    for i in range(numCat):
        # load labelled digit data
        saveName = dataType+catNames[i]+'Data.csv'
        digitData = np.genfromtxt(saveName, delimiter=',')
        # get X, y from data
        X = digitData[:,:(n)]
        y = digitData[:,(n)]
        # add Xo = 1 into X
        Xcalc       = np.zeros((m,n+1)) 
        Xcalc[:,1:] = X.copy()
        Xcalc[:,0]  = 1

        # normalise X
        Xcalc = (Xcalc - mu[:,i]) / sigma[:,i]

        # generate hypothesis for each training example
        yCalcArr = np.zeros((m,numCat))
        for j in range(numCat):
            yCalcRaw        = np.dot(Xcalc,theta[:,j])
            yCalcArr[:,j]   = sigmoid(yCalcRaw)
        yCalc = np.zeros(m)
        for j in range(m):
            bestEst = np.where(yCalcArr[j,:]==max(yCalcArr[j,:]))[0][0]
            if bestEst == i:
                yCalc[j] = 1
            else:
                yCalc[j] = 0
        
        # compare calc Y to true Y
        correct = 100*(yCalc==y).sum()/float(m)
        print 'category',catNames[i]       
        print 'hypothesis generated by logistic regression produces ',correct,' percent \ncorrect classifications of training data'

# =============================================================================== #

def loadBinData(folderName,n):
    """
    populates X and y matrix for logistic regression
    loads data from input folderName using n features
    """
	
    # load up files
    DIR = os.path.normpath('elementLibrary/processed/'+folderName)
    imageList = [name for name in os.listdir(DIR)if os.path.isfile(os.path.join(DIR, name))]
    m = len(imageList)
    print m,'training examples'

    # initialise matrices
    X = np.zeros((m,n))     # input examples for training
    y = np.zeros(m)         # output examples for training
	
    # populate matrices for each training example
    for i in range(m):
	# get example file name
	imageName = imageList[i]

	# read example output data
	if imageName[0:3] == 'YES':
	    y[i] = 1 # positive case
	elif imageName[0:3] == 'NOT':
	    y[i] = 0 # negative case
	else:
	    raise ValueError('input files not named correctly')
        
	# read example input data
	readPath = os.path.normpath(DIR+'/'+imageName)
	imgArr = cv.imread(readPath,1)
	count = 0
	for column in range(numColumns):
	    for color in range(numColors):
		X[i,count] = imgArr[:,column,color].sum()
		count+=1
    return X,y,m

# =============================================================================== #

def saveResults(saveName,numCat,numFeat,dataType,catNames,comments,theta,mu,sigma):
    """
    save results of logistic regressions to .csv file
    should work for 1 category as well as 3+ - there should never be 2 categories
    INPUTS:
        saveName    - name to be saved eg. 'digit0.csv' - must include the .csv
        numCat      - number of categories to be sorted, must be at least 1
        numFeat     - number of features, ie. length of theta, includes bias, is effectively n+1
        dataType    - the data type being classified
        catNames    - list of names of each category ['name1','name2',etc...]
        comments    - string of commments for user to inspect
        theta       - numpy array of theta values with dimension numFeat x numCat
        mu          - numpy array of mu values with dimension numFeat x numCat
        sigma       - numpy array of sigma values with dimension numFeat x numCat
    """
    # prepare header
    header = comments+'\nnumCat,'+str(numCat)+'\nnumFeat,'+str(numFeat)+'\ndataType,'+dataType+'\ncatNames'
    for cat in catNames:
        header = header+','+cat
    header = header+'\ntheta 1'
    for name in ['theta ','mu ','sigma ']:
        for i in range(1,numCat+1):
            if i == 1 and name == 'theta ':
                continue
            header = header +','+ name+str(i)

    # matrix to be saved
    Z = np.zeros((numFeat,numCat*3))
    
    # collate category parameters
    if numCat == 1:
        Z[:,0]  = theta
        Z[:,1]  = mu
        Z[:,2]  = sigma
    else:
        Z[:,0:numCat]           = theta
        Z[:,numCat:2*numCat]    = mu
        Z[:,2*numCat:3*numCat]  = sigma
    # save collated parameters to .csv file
    np.savetxt(saveName,Z,delimiter=',',header=header)
    print 'theta values saved to ',saveName

# =============================================================================== #

def loadResults(readName,loadMulti=True):
    """
    loads parameters for a logistic regression from a .csv file saved using saveResults
    returns parameters
    """


    results = np.genfromtxt(readName, delimiter=',')

    # ===== get descriptive data ===== #
    
    #print 'loading parameter file:',readName
    header = open(readName)
    header.readline()#print 'file comment:\t',header.readline()[2:]
    numCat      = int(header.readline()[2:].split(',')[1])
    numFeat     = int(header.readline()[2:].split(',')[1])
    dataType    = header.readline()[2:].split(',')[1]
    catNames    = header.readline()[2:].split(',')[1:]
    dataType    = dataType[:-1] # get rid of \n at end
    catNames[-1]    = catNames[-1][:-1] # get rid of \n at end

    # ===== get theta, mu, sigma ===== #
    if loadMulti:
        theta   = np.zeros((numFeat,numCat))
        mu      = np.zeros((numFeat,numCat))
        sigma   = np.zeros((numFeat,numCat))

        for c in range(numCat):
            theta[:,c]  = results[:,c           ] 
            mu[:,c]     = results[:,c + numCat  ] 
            sigma[:,c]  = results[:,c + 2*numCat]
    else:
        theta   = np.zeros(numFeat)
        mu      = np.zeros(numFeat)
        sigma   = np.zeros(numFeat)

        theta  = results[:,0] 
        mu     = results[:,1] 
        sigma  = results[:,2]

    if loadMulti:
        return numCat,numFeat,dataType,catNames,theta,mu,sigma
    else:
        return numFeat,dataType,theta,mu,sigma

# =============================================================================== #

def classifyImage(imgArr,imgType,parameterName):
    """
    does binary classification only
    """
    # ===== load data ===== #
    # hypothesis parameters
    path    = os.path.normpath('learningData/'+parameterName)
    (numFeat,dataType,theta,mu,sigma) = loadResults(path,loadMulti=False)

    # fill X - input data for classfication
    if imgType == 'faceCardExists':
        # faceCard specific parameters
        numColumns = 13
        numColors = 3
        n = numColumns*numColors
        X = np.zeros((1,n))
        count = 0
        for column in range(numColumns):
            for color in range(numColors):
                X[0,count] = imgArr[:,column,color].sum()
                count+=1
    else:
        raise ValueError('no classification for image of that type')

    # ===== classify image ===== #
        
    # add Xo = 1 into X
    (m,n)       = X.shape
    Xcalc       = np.zeros((m,n+1)) 
    Xcalc[:,1:] = X.copy()
    Xcalc[:,0]  = 1

    # normalise Xcalc
    for i in range(m):
        Xcalc[i,:] = (Xcalc[i,:] - mu) / sigma  
    # calculate hypothesis
    yCalcRaw = np.dot(Xcalc,theta)
    yCalc = sigmoid(yCalcRaw)
        
    if yCalc>0.5:
        return True
    else:
        return False

# =============================================================================== #

def classifyMultiImage(imgArr,imgType,parameterName):
    """
    does one vs all classification only
    currently only works for digits
    will have to add suits too
    consider adding this info to parameter files so that this can be automated more simply
    """
    if imgType == 'digit':
        numCol = 6
        numRow = 10
    elif imgType == 'betDigit':
	numCol = 5
	numRow = 8
    elif imgType == 'suit':
        numCol = 9
        numRow = 0
    elif imgType == 'cardVal':
        numCol = 7
        numRow = 13
    else:
        raise ValueError('invalid image type')
   
    # load hypothesis function (theta values)
    path    = os.path.normpath('learningData/'+parameterName)
    (numCat,numFeat,dataType,catNames,theta,mu,sigma) = loadResults(path)

    # get X (input data for classfication) from image data
    X = buildX(imgArr,dataType,numCol,numRow,isRGB=False)

    # add Xo = 1 into X
    Xcalc       = np.zeros(numFeat) 
    Xcalc[1:]   = X.copy()
    Xcalc[0]    = 1
    yCalcArr    = np.zeros(numCat)

    # generate hypothesis for each digit
    for i in range(numCat): 
        # normalise X
        XcalcCat = (Xcalc - mu[:,i]) / sigma[:,i]

        # generate hypothesis
        yCalcRaw        = np.dot(XcalcCat,theta[:,i])
        yCalcArr[i]     = sigmoid(yCalcRaw)
        
    bestEst = np.where(yCalcArr==yCalcArr.max())[0][0]
    catEst = catNames[bestEst]
    #print yCalcArr
    #print 'best estimate index',bestEst,'classifies digit as',catEst
    return catEst

# =============================================================================== #

def buildX(imgArr,dataType,numCol,numRow,isRGB=True):
    """
    builds the training matrix X
    NEEDS A REWORK
    """
    # builds a single row of X - ie, one input
    if dataType == 'digit' or dataType == 'suit' or dataType == 'betDigit':
        if isRGB:
            imgArr = imgArr[:,:,0]
            imgArr[imgArr>0] = 1
        X = np.zeros(numCol+numRow)
        # load features
        for col in range(numCol):
            X[col] = imgArr[:,col].sum()
        for row in range(numRow):
            feat = numCol+row
            X[feat] = imgArr[row,:].sum()
        return X
    elif dataType == 'cardVal':
        numCol = 7
        numRow = 13
        if isRGB:
            imgArr = imgArr[:,:,0]
            imgArr[imgArr>0] = 1
        X = np.zeros(numCol+numRow)
        # load features
        for col in range(numCol):
            X[col] = imgArr[:,col].sum()
        for row in range(numRow):
            feat = numCol+row
            X[feat] = imgArr[row,:].sum()
        return X
    else:
        raise ValueError('invalid dataType')
    
# =============================================================================== #

# ===== run main ===== #
if __name__ == '__main__':
    multiClassify()
    #binaryClassify()
    #findErrors()

# =============================================================================== #







